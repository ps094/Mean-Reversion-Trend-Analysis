{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Live_Strategy_Filter\n",
    "import Config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import copy\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "client=MongoClient(Config.DB_Hostname,Config.DB_Port)\n",
    "import multiprocessing\n",
    "\n",
    "class Live_Strategy_Simulator:\n",
    "    \n",
    "    def __init__(self, parameters, simulation_parameters, analysis_start_date):\n",
    "        \n",
    "        '''\n",
    "        parameters = {\"start_date\" : \"2022-04-22\",\n",
    "                      \"end_date\" : \"2023-10-13\", \n",
    "                      \"prediction_date\" : '2023-10-13'}\n",
    "        \n",
    "        simulation_parameters = {\"rolling_periods\" : [50, 100, 150, -1], \n",
    "                                   \"zero_rtd_flag\" : [True, False],\n",
    "                                   \"outlier_flag\": [True, False], \n",
    "                                   \"train_sample_size\" : [20, 40, 50],\n",
    "                                   \"test_sample_size\" : [5, 10, 20],\n",
    "                                   \"maximize_returns\" : [True, False],\n",
    "                                   \"top_n\" : [1, 2, 3]}\n",
    "                                   \n",
    "        analysis_start_date = {10 : \"2023-06-09\", 20 : \"2023-05-26\", 30 : \"2023-05-12\", 40 : \"2023-04-27\"}\n",
    "        '''\n",
    "        \n",
    "        self.parameters = copy.deepcopy(parameters)\n",
    "        self.simulation_parameters = copy.deepcopy(simulation_parameters)\n",
    "        self.analysis_start_date = copy.deepcopy(analysis_start_date)\n",
    "        \n",
    "        self.parameter_map = {}\n",
    "        self._create_simulation_parameter_map()\n",
    "        \n",
    "    def _create_simulation_parameter_map(self):\n",
    "        \n",
    "        identifier = 1\n",
    "        \n",
    "        for rolling_periods in self.simulation_parameters[\"rolling_periods\"]:\n",
    "            \n",
    "            for zero_rtd_flag in self.simulation_parameters[\"zero_rtd_flag\"]:\n",
    "                \n",
    "                        for outlier_flag in self.simulation_parameters[\"outlier_flag\"]:\n",
    "                        \n",
    "                                self.parameter_map[identifier] = {\"rolling_periods\" : rolling_periods, \n",
    "                                                                  \"zero_rtd_flag\" : zero_rtd_flag, \n",
    "                                                                  \"outlier_flag\" : outlier_flag,\n",
    "                                                                  \"train_sample_size\" : None,\n",
    "                                                                  \"test_sample_size\" : None,\n",
    "                                                                  \"maximize_returns\" : None}\n",
    "                                identifier+=1\n",
    "    \n",
    "    def _initial_simulation(self):\n",
    "        \n",
    "        params_list = []\n",
    "        for identifier, simulation_parameters in self.parameter_map.items():\n",
    "            \n",
    "            params_list.append({\"simulation_parameters\": copy.deepcopy(simulation_parameters),\n",
    "                      \"parameters\": copy.deepcopy(self.parameters),\n",
    "                      \"identifier\" : identifier})\n",
    "        \n",
    "        \n",
    "        with multiprocessing.Pool() as pool:\n",
    "            res = pool.map(Live_Strategy_Filter.Simulate, iterable = params_list)\n",
    "\n",
    "        sim_results = pd.concat(res)\n",
    "        sim_results.to_csv('sim_res.csv')\n",
    "        \n",
    "        '''\n",
    "        sim_results = pd.read_csv('sim_res.csv').drop(columns = ['Unnamed: 0'])\n",
    "        '''\n",
    "        \n",
    "        sim_results.sort_values(['date', 'identifier', 'current_week_limit', 'next_week_limit', 'rtd_threshold_lower', 'rtd_threshold_upper'], inplace=True)\n",
    "        print(\"Initial Simulation Complete\")\n",
    "        return sim_results\n",
    "\n",
    "    def _calc_portfolio_performance(self, temp_sim, split_dates):\n",
    "\n",
    "        if split_dates is None:\n",
    "            \n",
    "            returns = temp_sim.sort_values('date').groupby('date').mean().returns\n",
    "            drawdown = copy.deepcopy(returns)\n",
    "            drawdown[drawdown > 0] = 0\n",
    "            return {\"average_returns\" : np.mean(returns),\n",
    "                    \"absolute_return_volatility\" : np.std(returns),\n",
    "                    \"average_MDD\" : np.mean(drawdown)}\n",
    "        \n",
    "        else:\n",
    "            split_dates = sorted(split_dates)\n",
    "            average_returns_list = []\n",
    "            average_MDD_list =[]\n",
    "\n",
    "            for i in range(len(split_dates)):\n",
    "\n",
    "                if i==0:\n",
    "                    temp = temp_sim[temp_sim.date <= split_dates[i]]\n",
    "                else:\n",
    "                    temp = temp_sim[(temp_sim.date > split_dates[i-1]) & (temp_sim.date <= split_dates[i])]\n",
    "\n",
    "                cumulative_returns = (1 + temp.groupby('date').mean().returns).cumprod()\n",
    "                average_MDD = min(-1 + cumulative_returns/cumulative_returns.cummax().apply(lambda x: max(1, x)))\n",
    "                average_returns = cumulative_returns.tolist()[-1]**(1/len(temp.date.unique())) - 1\n",
    "                average_returns_list.append(average_returns)\n",
    "                average_MDD_list.append(average_MDD)\n",
    "\n",
    "            return {\"average_returns\" : np.mean(average_returns_list),\n",
    "                    \"absolute_return_volatility\" : np.std(average_returns_list),\n",
    "                    \"average_MDD\" : np.mean(average_MDD_list)}\n",
    "\n",
    "    def _filter_best_micro_params(self, simulation, maximize_returns = True, top_n = 1):\n",
    "\n",
    "        sim = copy.deepcopy(simulation)\n",
    "        current_week_limit_list = []\n",
    "        next_week_limit_list = []\n",
    "        rtd_threshold_lower_list = []\n",
    "        rtd_threshold_upper_list = []\n",
    "\n",
    "        average_returns = []\n",
    "        absolute_return_volatility = []\n",
    "        average_MDD = []\n",
    "    \n",
    "        performance = pd.DataFrame()\n",
    "        date_list = sorted(sim.date.unique())\n",
    "        split_dates = None\n",
    "\n",
    "        for current_week_limit in sorted(sim.current_week_limit.unique().tolist()):\n",
    "            for next_week_limit in sorted(sim.next_week_limit.unique().tolist()):\n",
    "                for rtd_threshold_lower, rtd_threshold_upper in sorted(set((zip(sim.rtd_threshold_lower, sim.rtd_threshold_upper)))):\n",
    "\n",
    "                    current_week_limit_list.append(current_week_limit)\n",
    "                    next_week_limit_list.append(next_week_limit)\n",
    "                    rtd_threshold_lower_list.append(rtd_threshold_lower)\n",
    "                    rtd_threshold_upper_list.append(rtd_threshold_upper)\n",
    "\n",
    "                    temp_sim = sim[(sim.current_week_limit == current_week_limit) & \n",
    "                                   (sim.next_week_limit == next_week_limit) & \n",
    "                                   (sim.rtd_threshold_lower == rtd_threshold_lower) &\n",
    "                                   (sim.rtd_threshold_upper == rtd_threshold_upper)]\n",
    "\n",
    "                    perf = self._calc_portfolio_performance(temp_sim, split_dates)\n",
    "                    average_returns.append(perf[\"average_returns\"])\n",
    "                    absolute_return_volatility.append(perf[\"absolute_return_volatility\"])\n",
    "                    average_MDD.append(perf[\"average_MDD\"])\n",
    "\n",
    "        performance[\"current_week_limit\"] = current_week_limit_list\n",
    "        performance[\"next_week_limit\"] = next_week_limit_list\n",
    "        performance[\"rtd_threshold_lower\"] = rtd_threshold_lower_list\n",
    "        performance[\"rtd_threshold_upper\"] = rtd_threshold_upper_list\n",
    "        performance[\"average_returns\"] = average_returns\n",
    "        performance[\"absolute_return_volatility\"] = absolute_return_volatility\n",
    "        performance[\"average_MDD\"] = average_MDD        \n",
    "        performance[\"sharpe\"] = np.where(performance.absolute_return_volatility == 0, \n",
    "                                         np.where(performance.average_returns == 0, 0, np.where(performance.average_returns>0, np.inf, -np.inf)), \n",
    "                                         performance.average_returns / performance.absolute_return_volatility)\n",
    "\n",
    "        performance = performance[performance.average_MDD >= performance.average_MDD.quantile(0.1)]\n",
    "        performance = performance[performance.sharpe >= performance.sharpe.quantile(0.9)]\n",
    "\n",
    "        if maximize_returns:\n",
    "            performance.sort_values(['average_returns', 'absolute_return_volatility', 'current_week_limit', \n",
    "                                     'next_week_limit', 'rtd_threshold_lower', 'rtd_threshold_upper', 'average_MDD'], \n",
    "                                    ascending = [False, True, False, False, False, True, False], inplace = True)\n",
    "\n",
    "        else:\n",
    "            performance.sort_values(['absolute_return_volatility', 'average_returns', 'current_week_limit', \n",
    "                                     'next_week_limit', 'rtd_threshold_lower', 'rtd_threshold_upper', 'average_MDD'], \n",
    "                                    ascending = [True, False, False, False, False, True, False], inplace = True)\n",
    "        \n",
    "        return performance.head(top_n).to_dict('records')\n",
    "        '''\n",
    "        {'current_week_limit': 1,\n",
    "         'next_week_limit': 1,\n",
    "         'rtd_threshold_lower': 0,\n",
    "         'rtd_threshold_upper': 100,\n",
    "         'average_returns': 0.045103822092706025,\n",
    "         'absolute_return_volatility': 0.011403502790589215,\n",
    "         'average_MDD': -0.23581863551409965,\n",
    "         'sharpe': 3.955260319656179}\n",
    "        '''\n",
    "\n",
    "    def _date_simulator(self, date_list, sim, macro_parameter):\n",
    "\n",
    "        main_sim = []\n",
    "        previous_train_date = None\n",
    "        previous_train_index = None\n",
    "\n",
    "        current_train_date = None\n",
    "        current_train_index = None\n",
    "\n",
    "        current_test_date = None\n",
    "        current_test_index = None\n",
    "\n",
    "        while current_test_index != len(date_list):\n",
    "\n",
    "            if previous_train_index is None:\n",
    "                previous_train_index = 0\n",
    "                current_train_index = macro_parameter[\"train_sample_size\"]\n",
    "            else:\n",
    "                previous_train_index += macro_parameter[\"test_sample_size\"]\n",
    "                current_train_index += macro_parameter[\"test_sample_size\"]\n",
    "\n",
    "            if len(date_list) - (current_train_index + macro_parameter[\"test_sample_size\"]) - 1 < 0.5 * macro_parameter[\"test_sample_size\"]:\n",
    "                current_test_index = len(date_list)\n",
    "\n",
    "            else:\n",
    "                current_test_index = current_train_index + macro_parameter[\"test_sample_size\"]\n",
    "\n",
    "            previous_train_date = date_list[previous_train_index] #include in train\n",
    "            current_train_date = date_list[current_train_index-1] #include in train exclude in test\n",
    "            current_test_date = date_list[current_test_index-1] #include in test\n",
    "\n",
    "            #train\n",
    "            temp_sim = sim[(sim.date >= previous_train_date) & (sim.date <= current_train_date)]\n",
    "            train_params_list = self._filter_best_micro_params(temp_sim, \n",
    "                                                          maximize_returns = macro_parameter[\"maximize_returns\"], \n",
    "                                                          top_n = macro_parameter[\"top_n\"])\n",
    "            \n",
    "            main_sim_temp = None\n",
    "            for train_params in train_params_list:\n",
    "                \n",
    "                temp_sim = sim[(sim.date > current_train_date) & (sim.date <= current_test_date) & \n",
    "                                    (sim.current_week_limit == train_params[\"current_week_limit\"]) &\n",
    "                                    (sim.next_week_limit == train_params[\"next_week_limit\"]) &\n",
    "                                    (sim.rtd_threshold_lower == train_params[\"rtd_threshold_lower\"]) &\n",
    "                                    (sim.rtd_threshold_upper == train_params[\"rtd_threshold_upper\"])]\n",
    "                \n",
    "                if main_sim_temp is None:\n",
    "                    main_sim_temp = copy.deepcopy(temp_sim)\n",
    "                else:\n",
    "                    dummy_date_list = main_sim_temp[main_sim_temp.underlying == \"DUMMY\"].date.unique()\n",
    "                    main_sim_temp = pd.concat([main_sim_temp[~main_sim_temp.date.isin(dummy_date_list)], temp_sim[temp_sim.date.isin(dummy_date_list)]])                    \n",
    "                    \n",
    "            main_sim.append(main_sim_temp)\n",
    "\n",
    "        main_sim = pd.concat(main_sim).sort_values('date')\n",
    "        \n",
    "        #create splitting dates for performance evaluation\n",
    "        i = -1\n",
    "        split_dates = []\n",
    "        date_list_temp = sorted(main_sim.date.unique())\n",
    "        while i != len(date_list_temp) - 1:\n",
    "            i = min(i+5, len(date_list_temp) - 1)\n",
    "            split_dates.append(date_list_temp[i])\n",
    "\n",
    "        #evaluate performance and return\n",
    "        return self._calc_portfolio_performance(main_sim, split_dates)\n",
    "    \n",
    "    def Hyperparameter_Tuner(self):\n",
    "        \n",
    "        \n",
    "        sim_results = self._initial_simulation()\n",
    "        sim_results.sort_values(['date', 'identifier'], inplace = True)\n",
    "        performance_summary = []\n",
    "\n",
    "        for identifier, simulation_parameters in self.parameter_map.items():\n",
    "            \n",
    "            start = time.time()\n",
    "            print(f\"Identifier : {identifier}\")\n",
    "            sim = sim_results[sim_results.identifier == identifier]\n",
    "            macro_parameter = copy.deepcopy(self.parameter_map[identifier])\n",
    "            date_list = sorted(sim.date.unique())\n",
    "            \n",
    "            for train_sample_size in self.simulation_parameters[\"train_sample_size\"]:\n",
    "                \n",
    "                for test_sample_size in self.simulation_parameters[\"test_sample_size\"]:\n",
    "                    \n",
    "                    for maximize_returns in self.simulation_parameters[\"maximize_returns\"]:\n",
    "                        \n",
    "                        for top_n in self.simulation_parameters[\"top_n\"]:\n",
    "                        \n",
    "                            macro_parameter[\"train_sample_size\"] = train_sample_size\n",
    "                            macro_parameter[\"test_sample_size\"] = test_sample_size\n",
    "                            macro_parameter[\"maximize_returns\"] = maximize_returns\n",
    "                            macro_parameter[\"top_n\"] = top_n\n",
    "\n",
    "                            perf = self._date_simulator(date_list, \n",
    "                                                        sim[sim.date >= self.analysis_start_date[train_sample_size]], \n",
    "                                                        macro_parameter)\n",
    "                            perf.update(macro_parameter)\n",
    "                            performance_summary.append(perf)\n",
    "                            \n",
    "            print(f\"Took {(time.time() - start)/60} minutes\")\n",
    "                        \n",
    "        performance_summary = pd.DataFrame(performance_summary)\n",
    "        performance_summary[\"date\"] = self.parameters['prediction_date']\n",
    "        performance_summary.to_csv('performance_summary.csv')\n",
    "\n",
    "        performance_summary[\"sharpe\"] = np.where(performance_summary.absolute_return_volatility == 0, \n",
    "                                         np.where(performance_summary.average_returns == 0, 0, np.where(performance_summary.average_returns>0, np.inf, -np.inf)), \n",
    "                                         performance_summary.average_returns / performance_summary.absolute_return_volatility)\n",
    "\n",
    "        performance_summary = performance_summary[performance_summary.average_MDD >= performance_summary.average_MDD.quantile(0.5)]\n",
    "        performance_summary = performance_summary[performance_summary.sharpe >= performance_summary.sharpe.quantile(0.9)]\n",
    "        performance_summary.sort_values(['average_returns', 'absolute_return_volatility', 'average_MDD', 'top_n'], ascending = [False, True, False, True], inplace = True)\n",
    "\n",
    "        print(client.Strategy.Profit_Maximizing_Hyperparams.delete_many({\"date\" : self.parameters[\"prediction_date\"]}).deleted_count, f\" records deleted Strategy.Profit_Maximizing_Hyperparams\")\n",
    "        print(len(client.Strategy.Profit_Maximizing_Hyperparams.insert_many(performance_summary.to_dict('records')[:1]).inserted_ids), f\" records inserted for Strategy.Profit_Maximizing_Hyperparams\")\n",
    "        \n",
    "        return performance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f807ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"start_date\" : \"2022-04-22\",\n",
    "              \"end_date\" : \"2023-12-29\", \n",
    "              \"prediction_date\" : \"2023-12-29\"}\n",
    "\n",
    "simulation_parameters = {\"rolling_periods\" : [150, 200, 250, -1], \n",
    "                         \"zero_rtd_flag\" : [True, False],\n",
    "                         \"outlier_flag\": [True, False], \n",
    "                         \"train_sample_size\" : [10, 20, 30, 40],\n",
    "                         \"test_sample_size\" : [5, 10],\n",
    "                         \"maximize_returns\" : [True, False], \n",
    "                         \"top_n\" : [1, 2, 3]}\n",
    "\n",
    "analysis_start_date = {10 : \"2023-06-09\", 20 : \"2023-05-26\", 30 : \"2023-05-12\", 40 : \"2023-04-27\"}\n",
    "\n",
    "self = Live_Strategy_Simulator(parameters, simulation_parameters, analysis_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8496c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "performance_summary = self.Hyperparameter_Tuner()\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a893c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#performance_summary.to_csv('performance_summary.csv')\n",
    "\n",
    "performance_summary = pd.read_csv('performance_summary.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "performance_summary[\"sharpe\"] = np.where(performance_summary.absolute_return_volatility == 0, \n",
    "                                 np.where(performance_summary.average_returns == 0, 0, np.where(performance_summary.average_returns>0, np.inf, -np.inf)), \n",
    "                                 performance_summary.average_returns / performance_summary.absolute_return_volatility)\n",
    "\n",
    "performance_summary = performance_summary[performance_summary.average_MDD >= performance_summary.average_MDD.quantile(0.5)]\n",
    "performance_summary = performance_summary[performance_summary.sharpe >= performance_summary.sharpe.quantile(0.95)]\n",
    "performance_summary.sort_values(['average_returns', 'absolute_return_volatility', 'average_MDD', 'top_n'], ascending = [False, True, False, True], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf0cc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "performance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(client.Strategy.Profit_Maximizing_Hyperparams.insert_many(performance_summary.head(1).to_dict('records')).inserted_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
